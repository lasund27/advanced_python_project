import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import pandas as pd
import re

st.set_page_config(page_title="OP.GG ì±”í”¼ì–¸ ìš”ì•½", layout="wide")

st.title("ğŸ”¥ OP.GG ì±”í”¼ì–¸ ë¶„ì„ê¸°")

# --- ì…ë ¥ ---
user_input = st.text_input("ì†Œí™˜ì‚¬ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: lasund72#7227)", value="")

if not user_input or "#" not in user_input:
    st.info("ë‹‰ë„¤ì„#íƒœê·¸ í˜•íƒœë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: Hide on bush#KR1")
    st.stop()

nickname, tag = user_input.split("#", 1)
encoded_name = f"{quote(nickname)}-{quote(tag)}"

# --- URL êµ¬ì„± ---
BASE_URL = "https://op.gg/ko/lol/summoners/kr"
CHAMPIONS_URL = f"{BASE_URL}/{encoded_name}/champions"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122 Safari/537.36"
}

# --- HTML ìš”ì²­ ---
def fetch(url):
    try:
        res = requests.get(url, headers=HEADERS, timeout=10)
        res.raise_for_status()
        return res.text
    except Exception as e:
        st.error(f"í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

# --- ì±”í”¼ì–¸ í˜ì´ì§€ íŒŒì‹± ---
def parse_champions(html):
    soup = BeautifulSoup(html, "html.parser")

    champs = []
    rows = soup.select("tr, div.ChampionBox, div.champion")  # ìœ ì—°í•œ ì„ íƒì

    # â€œëª¨ë“  ì±”í”¼ì–¸â€ í–‰ì„ ì œì™¸í•˜ê¸° ìœ„í•´ ì²« ë²ˆì§¸ í–‰ ìŠ¤í‚µ
    valid_rows = []
    for r in rows:
        text = r.get_text(" ", strip=True)
        if "ëª¨ë“  ì±”í”¼ì–¸" in text:
            continue  # skip this
        if "vs" in text:
            continue  # skip VS ë°ì´í„°
        if re.search(r"ìŠ¹|íŒ¨|%", text):  # ì±”í”¼ì–¸ í†µê³„ê°€ í¬í•¨ëœ í–‰ë§Œ
            valid_rows.append(r)

    # ìƒìœ„ 5ê°œë§Œ
    valid_rows = valid_rows[:5]

    for r in valid_rows:
        img_tag = r.select_one("img[src*='champion']")
        img = img_tag.get("src") if img_tag else None
        name = img_tag.get("alt") if img_tag else "Unknown"

        text = r.get_text(" ", strip=True)
        winrate = re.search(r"(\d{1,3}\.?\d*)%", text)
        wins = re.search(r"(\d+)\s*ìŠ¹", text)
        losses = re.search(r"(\d+)\s*íŒ¨", text)

        champs.append({
            "name": name,
            "img": img,
            "winrate": winrate.group(1) + "%" if winrate else "-",
            "wins": wins.group(1) if wins else "-",
            "losses": losses.group(1) if losses else "-"
        })

    return champs

# --- ì‹¤í–‰ ---
with st.spinner("OP.GGì—ì„œ ì±”í”¼ì–¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    html = fetch(CHAMPIONS_URL)

if not html:
    st.error("í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

champions = parse_champions(html)

if not champions:
    st.warning("ì±”í”¼ì–¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ì¶œë ¥ ---
st.header("ğŸ¯ ëª¨ìŠ¤íŠ¸í”½ ì±”í”¼ì–¸ Top 5")

for i, c in enumerate(champions, start=1):
    cols = st.columns([1, 4])
    with cols[0]:
        if c["img"]:
            st.image(c["img"], width=70)
    with cols[1]:
        st.subheader(f"{i}. {c['name']}")
        st.write(f"ìŠ¹ë¥ : **{c['winrate']}**")
        st.write(f"ìŠ¹ë¦¬: {c['wins']}íšŒ / íŒ¨ë°°: {c['losses']}íšŒ")

st.markdown("---")
st.caption(f"ë°ì´í„° ì¶œì²˜: [OP.GG]({CHAMPIONS_URL})")
